{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract\n",
    "import pandas as pd\n",
    "import ipaddress as ip\n",
    "from os.path import splitext\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Training Url set*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/rlilojr/Detecting-Malicious-URL-Machine-Learning/master/dataset.csv\")\n",
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranining Urls and Model Feeding Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=df.head(113874)\n",
    "data_test.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few suspicious TLD and Words\n",
    "Suspicious_TLD=['zip','cricket','link','work','party','gq','kim','country','science','tk','surf','cn','ga','cf','ml','tokyo','top']\n",
    "\n",
    "# Suspicious Domains\n",
    "Suspicious_Domain=['luckytime.co.kr','mattfoll.eu.interia.pl','trafficholder.com','dl.baixaki.com.br','bembed.redtube.comr','tags.expo9.exponential.com','deepspacer.com','funad.co.kr','trafficconverter.biz']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Defining Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotCount(url):\n",
    "    return url.count('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delimCount(url):\n",
    "    delim=[';','_','?','=','&']\n",
    "    for item in url:\n",
    "        if item in delim:\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isip(uri):\n",
    "    try:\n",
    "        if ip.ip_address(uri):\n",
    "            return 1\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifHyphen(url):\n",
    "    return url.count('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifAt(url):\n",
    "    return url.count('@')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifDoubleSlash(url):\n",
    "    return url.count('//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSubDir(url):\n",
    "    return url.count('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExtension(url):\n",
    "    \"\"\"Return the file Extension from the URL such as '.html','.php',etc\"\"\"\n",
    "    \n",
    "    root, ext = splitext(url)\n",
    "    return ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countSubDomain(subdomain):\n",
    "    if not subdomain:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(subdomain.split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queriesCount(query):\n",
    "    if not query:\n",
    "        return 0 \n",
    "    else:\n",
    "        return len(query.split('&'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function Defination Done!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function Initialisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(url, label):\n",
    "    result = []\n",
    "    url = str(url)\n",
    "    \n",
    "    # Adding inputs to the 'result' list\n",
    "    result.append(url)\n",
    "    \n",
    "    path = urlparse(url)\n",
    "    ext = tldextract.extract(url)\n",
    "\n",
    "    result.append(dotCount(ext.subdomain))\n",
    "\n",
    "    result.append(ifHyphen(path.netloc))\n",
    "\n",
    "    result.append(len(url))\n",
    "\n",
    "    result.append(ifAt(path.netloc))\n",
    "\n",
    "    result.append(ifDoubleSlash(path.path))\n",
    "\n",
    "    result.append(countSubDir(path.path))\n",
    "\n",
    "    result.append(countSubDomain(ext.subdomain))\n",
    "\n",
    "    result.append(len(path.netloc))\n",
    "\n",
    "    result.append(len(path.query))\n",
    "\n",
    "    result.append(isip(ext.domain))\n",
    "    \n",
    "    result.append(1 if ext.suffix in Suspicious_TLD else 0)\n",
    "\n",
    "    result.append(1 if '.'.join(ext[1:]) in Suspicious_Domain else 0)\n",
    "\n",
    "    result.append(str(label))\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet = pd.DataFrame(columns=('url','no of dots','presence of hyphen','len of url','presence of at',\\\n",
    "'presence of double slash','no of subdir','no of subdomain','len of domain','no of queries','is IP','presence of Suspicious_TLD',\\\n",
    "'presence of suspicious domain','label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_test)):\n",
    "    features = getFeatures(data_test['url'].loc[i], data_test['label'].loc[i])\n",
    "    featureSet.loc[i] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DataSet Processing is Done!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Visualization packages \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "from __future__ import division\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the length of the urls on both sides \n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.histplot(featureSet[featureSet['label']=='1']['len of url'], color='green',label='Benign URLs',kde=True)\n",
    "sns.histplot(featureSet[featureSet['label']=='0']['len of url'], color='red',label='Phishing URLs',kde=True)\n",
    "plt.xlabel('Length of URL')\n",
    "plt.legend(loc='upper right')\n",
    "plt.legend( loc='upper right')\n",
    "plt.xlabel('Length of URL')\n",
    "\n",
    "plt.title('Url Length Distribution')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of dots on both sides\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.histplot(featureSet[featureSet['label']=='1']['no of dots'], color='green',label='Benign URLs',kde=True)\n",
    "sns.histplot(featureSet[featureSet['label']=='0']['no of dots'], color='red',label='Malicious URLs',kde=True)\n",
    "plt.xlabel('Number of Dot')\n",
    "plt.legend(loc='upper right')\n",
    "plt.legend( loc='upper right')\n",
    "plt.xlabel('Number  of Dot')\n",
    "\n",
    "plt.title('Distribution of Number of Dots in URL')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "sns.histplot(featureSet[featureSet['label']=='0']['len of domain'],color='red',label='Malicious URLs',kde=True)\n",
    "sns.histplot(featureSet[featureSet['label']=='1']['len of domain'],color='green',label='Benign URLs',kde=True)\n",
    "plt.title('Domain Length Distribution')\n",
    "plt.legend(loc='upper right')\n",
    "plt.legend( loc='upper right')\n",
    "plt.xlabel('Length of Domain/Host')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Report Generator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(cmatrix, score, creport):\n",
    "  \"\"\"Generates and displays graphical reports\n",
    "  Keyword arguments:\n",
    "    cmatrix - Confusion matrix generated by the model\n",
    "    score --- Score generated by the model\n",
    "    creport - Classification Report generated by the model\n",
    "    \n",
    "  :Returns -- N/A\n",
    "  \"\"\"\n",
    "  \n",
    "  # Generate confusion matrix heatmap\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cmatrix, \n",
    "              annot=True, \n",
    "              fmt=\"d\", \n",
    "              linewidths=.5, \n",
    "              square = True, \n",
    "              cmap = 'Reds', \n",
    "              annot_kws={\"size\": 16}, \n",
    "              xticklabels=['bad', 'good'],\n",
    "              yticklabels=['bad', 'good'])\n",
    "\n",
    "  plt.xticks(rotation='horizontal', fontsize=16)\n",
    "  plt.yticks(rotation='horizontal', fontsize=16)\n",
    "  plt.xlabel('Actual Label', size=20);\n",
    "  plt.ylabel('Predicted Label', size=20);\n",
    "\n",
    "  title = 'Accuracy Score: {0:.4f}'.format(score)\n",
    "  plt.title(title, size = 20);\n",
    "\n",
    "  # Display classification report and confusion matrix\n",
    "  print(creport)\n",
    "  plt.show();\n",
    "  \n",
    "\n",
    "print(\"\\n### Report Generator Defined ###\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Applying Models of the processed data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble as ek\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSet.groupby(featureSet['label']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = featureSet.drop(['url','label'],axis=1).values\n",
    "y = featureSet['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = { \"DecisionTree\":tree.DecisionTreeClassifier(max_depth=10),\n",
    "         \"RandomForest\":ek.RandomForestClassifier(n_estimators=50),\n",
    "         \"Adaboost\":ek.AdaBoostClassifier(n_estimators=50),\n",
    "         \"GradientBoosting\":ek.GradientBoostingClassifier(n_estimators=50),\n",
    "         \"GNB\":GaussianNB(),\n",
    "         \"LogisticRegression\":LogisticRegression(max_iter=1000)   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.3, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for algo in model:\n",
    "    clf = model[algo]\n",
    "    clf.fit(X_train,y_train)\n",
    "    score = clf.score(X_test,y_test)\n",
    "    print (f\"{algo} : {score}\")\n",
    "    results[algo] = score\n",
    "    \n",
    "print(\"*-\"*10)\n",
    "winner = max(results, key=results.get)\n",
    "print(f\"{winner}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Accuray of My model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = model[winner]\n",
    "print(clf)\n",
    "res = clf.predict(X)\n",
    "mt = confusion_matrix(y,res)\n",
    "report = classification_report(y,res)\n",
    "generate_report(mt,score,report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=('url','no of dots','presence of hyphen','len of url','presence of at','presence of double slash','no of subdir','no of subdomain','len of domain','no of queries','is IP','presence of Suspicious_TLD','presence of suspicious domain','label'))\n",
    "results = getFeatures('www..foofle.mo','0')\n",
    "result.loc[0] = results\n",
    "print(results)\n",
    "result = result.drop(['url','label'],axis=1).values\n",
    "print(clf.predict(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=('url','no of dots','presence of hyphen','len of url','presence of at',\\\n",
    "'presence of double slash','no of subdir','no of subdomain','len of domain','no of queries','is IP','presence of Suspicious_TLD',\\\n",
    "'presence of suspicious domain','label'))\n",
    "\n",
    "results = getFeatures('https://twitter.com/', '0')\n",
    "result.loc[0] = results\n",
    "print(results)\n",
    "result = result.drop(['url','label'],axis=1).values\n",
    "print(clf.predict(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_url = input(\"Enter the URl: \")\n",
    "\n",
    "result = pd.DataFrame(columns=('url','no of dots','presence of hyphen','len of url','presence of at',\\\n",
    "'presence of double slash','no of subdir','no of subdomain','len of domain','no of queries','is IP','presence of Suspicious_TLD',\\\n",
    "'presence of suspicious domain','label'))\n",
    "\n",
    "results = getFeatures(test_url, '0')\n",
    "result.loc[0] = results\n",
    "result = result.drop(['url','label'],axis=1).values\n",
    "output = clf.predict(result)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bf2ca0f4a7adc3ce2f237ca763c1538d3ef289a4e7face3612a01cdae9f6807"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
